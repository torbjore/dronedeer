---
title: "Results"
date: last-modified
number-sections: true
toc: true
toc-depth: 4
format:
  html:
    embed-resources: true
---

```{r}
#| echo: false
library(coda)
```

DETTE ER ET INTERNT ARBEIDSDOKUMENT - IKKE MENT FOR PUBLISERING

## Overview of raw data



## Checking convergence and WAIC models

```{r}
#| echo: false

# WAIC can be used even when we have different observation models: https://discourse.mc-stan.org/t/can-waic-looic-be-used-to-compare-models-with-different-likelihoods/7380

Path <- "../data/posterior_samples"
files <- dir(path = Path)
#files <- files[substring(files, 1, 3) != "pos"]
models <- c(
  "exponential_1",
  "lognormal_1",
  "gamma_1",
  "exponential_2",
  "lognormal_2",
  "gamma_2"
  )

for(mod in models){
  cat("\n **", mod, "**\n")
  fls <- files[grep(mod, files)]
  postsamp <- WAIC <- NULL
  for(fl in fls){
    load(paste0("../data/posterior_samples/", fl))
    postsamp <- c(postsamp, out$samples)
    WAIC <- c(WAIC, out$WAIC$WAIC)
  }
  postsamp <- as.mcmc.list(postsamp)
  cat("Number of runs:", length(fls), "\n")
  cat("Settings for each run:\n")
  print(unlist(settings))
  cat("\nConvergence diagnostics for all chains combined:\n")
  print(gelman.diag(postsamp))
  cat("\nWIAC in each run:", WAIC)
  cat("\nMean WIAC:", mean(WAIC), "\n")
}
```

The upper CI of the 'potential scale reduction factor' by Gelman and Rubin is a bit high for some models, so we should probably either run these models longer or do something to get better mixing.

Assuming that this convergence issue will not affect the WIAC-ranking of the models, the best model is 'gamma_2' (this model has pretty good convergence criteria, but we can run for longer to get even better).

## Posterior predictive checks of best model

```{r}
#| echo: false
# Loading best model
best <- "gamma_2"
fls <- files[grep(best, files)]
best_postsamp <- NULL
for(fl in fls){
  load(paste0("../data/posterior_samples/", fl))
  best_postsamp <- c(best_postsamp, out$samples)
}
best_postsamp <- as.mcmc.list(best_postsamp)
```

### Bayesian p-value based on Y

```{r}
#| echo: false
samp <- as.matrix(best_postsamp)
plot(samp[,"Disc_New_Y"] ~ samp[,"Disc_Y"])
abline(0, 1, col="red")
mean(samp[, "Disc_New_Y"] > samp[, "Disc_Y"])
```

### Bayesian p-value based on y

```{r}
#| echo: false

plot(samp[,"Disc_New_y"] ~ samp[,"Disc_y"])
abline(0, 1, col="red")
mean(samp[, "Disc_New_y"] > samp[, "Disc_y"])
```

### Conclusion

No indication of serious lack of fit.

## Summary of best model

```{r}
#| echo: false
summary(best_postsamp)
```

## Predictions from the best model

### Plot

```{r}
#| echo: false
#| warning: FALSE

Sys.setlocale(locale='no_NB.utf8')

library(ggplot2)
#library(hrbrthemes) # TE> Tar bort dette for jeg har ikke alle fontene som kreves installert på min maskin ser det ut til
library(cowplot)

source("utilities.r")

#############
# Preparing #
#############

load(file = "../data/UseData.rda")
load(file = "../data/Counts.rda")

sam_names <- c("Haugen (April)", "Haugen (March)", "Raa (April)", "Raa (March)", "Søre Bjørkum (April)", "Søre Bjørkum (March)", "Sprakehaug (April)", "Sprakehaug (March)")

predictor_variable <- UseData$mean_field_dist
Xlab <- "Distance from field (m)"
Ylab <- expression(Density~of~deer~(km^-2))

X <- seq(0, max(predictor_variable, na.rm = TRUE), length.out=50)
X_mean <-  mean(predictor_variable, na.rm=TRUE)
X_sd <- sd(predictor_variable, na.rm=TRUE)
X_st <- (X - X_mean)/X_sd

mpv <- mean(predictor_variable, na.rm = TRUE) # mean predictor variable
pap <- median(-samp[,"beta[1]"]/(2*samp[,"beta[2]"]))*X_sd + X_mean # predictor variable at peak

############
# Plotting #
############

plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])
```

* Mean distance from the field (stippled line): `r round(mpv, 0)` meters.
* Posterior median of distance at peak deer density (dotted line): `r round(pap, 0)` meters.

<!-- Posterior summary for distance at peak deer density: -->

<!-- ```{r} -->
<!-- #| echo: FALSE -->

<!-- quantile(-samp[,"beta[1]"]/(2*samp[,"beta[2]"]), probs = c(0.025, 0.5, 0.975))*X_sd + X_mean -->

<!-- ``` -->

### Table - Predictions at peak deer density (for table A3):

* Kommentar: Jeg har her brukt samme rekkefølge som i figuren (den rekkefølgen du har på plottene i manus), men table A3 har en annen rekkefølge. Jeg synes du skal bruke samme rekkefølge i figur og tabell. Kanskje du også skal forenkle å bare ta med posterior median, 2.5 percentil og 97.5 percentil - det er det jeg har gjort i plottet nå.

```{r}
#| echo: FALSE

df <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[SAM] <- mean(y)
  df$median[SAM] <- Q[2]
  df$lwr[SAM] <- Q[1]
  df$upr[SAM] <- Q[3]
}

print(df[c(2,1,4,3,6,5,8,7), ])

```

## Some sensitivity assessment

### Choice of radom distribution for $\lambda$

Predictions from each of the models at mean distance from field at Haugen in March:

```{r}
#| echo: false

i = 1
df <- data.frame(Model = models)
for(mod in models){
  fls <- files[grep(mod, files)]
  postsamp <- NULL
  for(fl in fls){
    load(paste0("../data/posterior_samples/", fl))
    postsamp <- c(postsamp, out$samples)
  }
  postsamp <- as.mcmc.list(postsamp) |> as.matrix()
  y <- pred(x=0, PS = postsamp, sam = 2)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[i] <- mean(y)
  df$median[i] <- Q[2]
  df$lwr[i] <- Q[1]
  df$upr[i] <- Q[3]
  i <- i+1
}
print(df)
```

Upper credible interval limit substantial higher for lognormal and gamma models than exponential models.

### Influence of restrictive prior for $\sigma_p$

Summaries from a model where I increased the upper limit of the the random effects SD for detection log-odds from 0.59 to 5.

```{r}
#| echo: FALSE

load("../data/posterior_samples/gam_2_test.RData")
gelman.diag(out$samples)
#plot(out$samples)
summary(out$samples)

samp <- as.matrix(out$samples)
plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])

df <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[SAM] <- mean(y)
  df$median[SAM] <- Q[2]
  df$lwr[SAM] <- Q[1]
  df$upr[SAM] <- Q[3]
}

print(df[c(2,1,4,3,6,5,8,7), ])

```

The results are, perhaps surprisingly, similar although the 'sigma_p' parameter is estimated very high. I think it is strange that 'sigma_p' is estimated so high, but good to see that it makes such a small difference of the results.

### Alternative prior for mu0

See files 'nimbleCode_DOMM_gamma_2_test.q' and 'fit_gamma_2_test.R'.

```{r}
#| echo: FALSE

load("../data/posterior_samples/gam_2_test_2.RData")
gelman.diag(out$samples)
#plot(out$samples)
summary(out$samples)

samp <- as.matrix(out$samples)
plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])

df2 <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df2$mean[SAM] <- mean(y)
  df2$median[SAM] <- Q[2]
  df2$lwr[SAM] <- Q[1]
  df2$upr[SAM] <- Q[3]
}

print(df2[c(2,1,4,3,6,5,8,7), ])
```

Sammenlignet med resultatet over:

```{r}
#| echo: FALSE

print(df[c(2,1,4,3,6,5,8,7), ])
```
