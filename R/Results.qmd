---
title: "Results"
date: last-modified
number-sections: true
toc: true
toc-depth: 4
format:
  html:
    embed-resources: true
---

```{r}
#| echo: false
library(coda)
```

DETTE ER ET INTERNT ARBEIDSDOKUMENT - IKKE MENT FOR PUBLISERING

## Overview of raw data

```{r}
#| echo: false
# Loading data
load(file = "../data/LDDdata.rda")
```

Numbers of deer seen per 'site and month' ('sam')

```{r}
#| echo: false
# Numbers seen in each 'site and month' (sam)
Y_per_sam <- apply(LDDdata$data$Y, 1, sum, na.rm=TRUE) |> tapply(INDEX = LDDdata$const$sam, sum)
sam_names <- c("Haugen (April)", "Haugen (March)", "Raa (April)", "Raa (March)", "Søre Bjørkum (April)", "Søre Bjørkum (March)", "Sprakehaug (April)", "Sprakehaug (March)")
names(Y_per_sam) <- sam_names
Y_per_sam
```

Simple point estimate of detectability

```{r}
colsumy <- apply(LDDdata$data$y, 3, sum, na.rm=TRUE)
p1hat <- colsumy[3]/(colsumy[2]+colsumy[3])
p2hat <- colsumy[3]/(colsumy[1]+colsumy[3])
(phat_simple <- 1 - (1-p1hat)*(1-p2hat))
#Y_per_sam/phat_simple

apply(LDDdata$const$area, 1, mean, na.rm=TRUE) 
```

Total area per 'sam' (unit = hectare)

```{r}
area_per_sam <- apply(LDDdata$const$area, 1, sum, na.rm=TRUE) |> tapply(INDEX = LDDdata$const$sam, sum)
(names(area_per_sam) <- sam_names)
area_per_sam
```

Simple density estimates per 'sam' (unit = number of deer per hectare)

```{r}
lambdahat <- (Y_per_sam/phat_simple)/area_per_sam
```

For the exponential model we can use the logarithms of these values to construct priors for 'mu0' (except for the sam's where there are zero observations). Initial models fitted to the data suggest that 'sigma' in the lognormal and gamma models is about 1.47, which means that the median is quite much lower than the mean (only about 1/3).

```{r}
log(lambdahat/exp(0.5*1.47^2))
```

To construct priors for 'mu0' I have used a normal distribution with the above means and the value of the standard deviation selected such that the 97.5% quantile of the prior distribution for median density, exp(mu0), is 100 times higher than the 2.5% quantile of the prior distribution

```{r}
round(log(100)/(2*1.96), 3)
```

The sam's where there are zero observations pose a problem. We cannot say much in terms of a point estimate or a lower confidence/credible interval in these cases, but there is some information about the upper confidence/credible interval (i.e, we can get some idea about how high the densities can potentially be).

To use the same prior-structure as for the other sams I computed prior mean densities from mcmc-samling with a Poisson-model as specified in the script 'prior_zero_sites.r' 

```{r}
lambdahat[3] <- 0.0066 # Raa (April)
lambdahat[4] <- 0.0046 # Raa (March)
lambdahat[7] <- 0.0047 # Sprakehaug (April)

log(lambdahat)
log(lambdahat/exp(0.5*1.47^2))
```



## Checking convergence and WAIC models

```{r}
#| echo: false

# WAIC can be used even when we have different observation models: https://discourse.mc-stan.org/t/can-waic-looic-be-used-to-compare-models-with-different-likelihoods/7380

Path <- "../data/posterior_samples"
files <- dir(path = Path)
#files <- files[substring(files, 1, 3) != "pos"]
models <- c(
  "exponential_1",
  "lognormal_1",
  "gamma_1",
  "exponential_2",
  "lognormal_2",
  "gamma_2"
  )

for(mod in models){
  cat("\n **", mod, "**\n")
  fls <- files[grep(mod, files)]
  postsamp <- WAIC <- NULL
  for(fl in fls){
    load(paste0("../data/posterior_samples/", fl))
    postsamp <- c(postsamp, out$samples)
    WAIC <- c(WAIC, out$WAIC$WAIC)
  }
  postsamp <- as.mcmc.list(postsamp)
  cat("Number of runs:", length(fls), "\n")
  cat("Settings for each run:\n")
  print(unlist(settings))
  cat("\nConvergence diagnostics for all chains combined:\n")
  print(gelman.diag(postsamp))
  cat("\nWIAC in each run:", WAIC)
  cat("\nMean WIAC:", mean(WAIC), "\n")
}
```

The upper CI of the 'potential scale reduction factor' by Gelman and Rubin is a bit high for some models, so we should probably either run these models longer or do something to get better mixing.

Assuming that this convergence issue will not affect the WIAC-ranking of the models, the best model is 'gamma_2' (this model has pretty good convergence criteria, but we can run for longer to get even better).

## Posterior predictive checks of best model

```{r}
#| echo: false
# Loading best model
best <- "gamma_2"
fls <- files[grep(best, files)]
best_postsamp <- NULL
for(fl in fls){
  load(paste0("../data/posterior_samples/", fl))
  best_postsamp <- c(best_postsamp, out$samples)
}
best_postsamp <- as.mcmc.list(best_postsamp)
```

### Bayesian p-value based on Y

```{r}
#| echo: false
samp <- as.matrix(best_postsamp)
plot(samp[,"Disc_New_Y"] ~ samp[,"Disc_Y"])
abline(0, 1, col="red")
mean(samp[, "Disc_New_Y"] > samp[, "Disc_Y"])
```

### Bayesian p-value based on y

```{r}
#| echo: false

plot(samp[,"Disc_New_y"] ~ samp[,"Disc_y"])
abline(0, 1, col="red")
mean(samp[, "Disc_New_y"] > samp[, "Disc_y"])
```

### Conclusion

No indication of serious lack of fit.

## Summary of best model

```{r}
#| echo: false
summary(best_postsamp)
```

## Predictions from the best model

### Plot

```{r}
#| echo: false
#| warning: FALSE

Sys.setlocale(locale='no_NB.utf8')

library(ggplot2)
#library(hrbrthemes) # TE> Tar bort dette for jeg har ikke alle fontene som kreves installert på min maskin ser det ut til
library(cowplot)

source("utilities.r")

#############
# Preparing #
#############

load(file = "../data/UseData.rda")
load(file = "../data/Counts.rda")

sam_names <- c("Haugen (April)", "Haugen (March)", "Raa (April)", "Raa (March)", "Søre Bjørkum (April)", "Søre Bjørkum (March)", "Sprakehaug (April)", "Sprakehaug (March)")

predictor_variable <- UseData$mean_field_dist
Xlab <- "Distance from field (m)"
Ylab <- expression(Density~of~deer~(km^-2))

X <- seq(0, max(predictor_variable, na.rm = TRUE), length.out=50)
X_mean <-  mean(predictor_variable, na.rm=TRUE)
X_sd <- sd(predictor_variable, na.rm=TRUE)
X_st <- (X - X_mean)/X_sd

mpv <- mean(predictor_variable, na.rm = TRUE) # mean predictor variable
pap <- median(-samp[,"beta[1]"]/(2*samp[,"beta[2]"]))*X_sd + X_mean # predictor variable at peak

############
# Plotting #
############

plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])
```

* Mean distance from the field (stippled line): `r round(mpv, 0)` meters.
* Posterior median of distance at peak deer density (dotted line): `r round(pap, 0)` meters.

<!-- Posterior summary for distance at peak deer density: -->

<!-- ```{r} -->
<!-- #| echo: FALSE -->

<!-- quantile(-samp[,"beta[1]"]/(2*samp[,"beta[2]"]), probs = c(0.025, 0.5, 0.975))*X_sd + X_mean -->

<!-- ``` -->

### Table - Predictions at peak deer density (for table A3):

* Kommentar: Jeg har her brukt samme rekkefølge som i figuren (den rekkefølgen du har på plottene i manus), men table A3 har en annen rekkefølge. Jeg synes du skal bruke samme rekkefølge i figur og tabell. Kanskje du også skal forenkle å bare ta med posterior median, 2.5 percentil og 97.5 percentil - det er det jeg har gjort i plottet nå.

```{r}
#| echo: FALSE

df <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[SAM] <- mean(y)
  df$median[SAM] <- Q[2]
  df$lwr[SAM] <- Q[1]
  df$upr[SAM] <- Q[3]
}

print(df[c(2,1,4,3,6,5,8,7), ])

```

## Some sensitivity assessment

### Choice of radom distribution for $\lambda$

Predictions from each of the models at mean distance from field at Haugen in March:

```{r}
#| echo: false

i = 1
df <- data.frame(Model = models)
for(mod in models){
  fls <- files[grep(mod, files)]
  postsamp <- NULL
  for(fl in fls){
    load(paste0("../data/posterior_samples/", fl))
    postsamp <- c(postsamp, out$samples)
  }
  postsamp <- as.mcmc.list(postsamp) |> as.matrix()
  y <- pred(x=0, PS = postsamp, sam = 2)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[i] <- mean(y)
  df$median[i] <- Q[2]
  df$lwr[i] <- Q[1]
  df$upr[i] <- Q[3]
  i <- i+1
}
print(df)
```

Upper credible interval limit substantial higher for lognormal and gamma models than exponential models.

### Influence of restrictive prior for $\sigma_p$

Summaries from a model where I increased the upper limit of the the random effects SD for detection log-odds from 0.59 to 5.

```{r}
#| echo: FALSE

load("../data/posterior_samples/gam_2_test.RData")
gelman.diag(out$samples)
#plot(out$samples)
summary(out$samples)

samp <- as.matrix(out$samples)
plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])

df <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df$mean[SAM] <- mean(y)
  df$median[SAM] <- Q[2]
  df$lwr[SAM] <- Q[1]
  df$upr[SAM] <- Q[3]
}

print(df[c(2,1,4,3,6,5,8,7), ])

```

The results are, perhaps surprisingly, similar although the 'sigma_p' parameter is estimated very high. I think it is strange that 'sigma_p' is estimated so high, but good to see that it makes such a small difference of the results.

### Alternative prior for mu0

See files 'nimbleCode_DOMM_gamma_2_test.q' and 'fit_gamma_2_test.R'.

```{r}
#| echo: FALSE

load("../data/posterior_samples/gam_2_test_2.RData")
gelman.diag(out$samples)
#plot(out$samples)
summary(out$samples)

samp <- as.matrix(out$samples)
plots <- pred_plots(PS = samp)

plot_grid(plots[[2]],
          plots[[1]],
          plots[[4]],
          plots[[3]])
plot_grid(plots[[6]],
          plots[[5]],
          plots[[8]],
          plots[[7]])

df2 <- data.frame(SAM = sam_names, x = pap)
pap_st <- (pap - X_mean)/X_sd
for(SAM in 1:length(sam_names)){
  y <- pred(pap_st, PS = samp, sam = SAM)
  Q <- quantile(y, probs = c(0.025, 0.5, 0.975))
  df2$mean[SAM] <- mean(y)
  df2$median[SAM] <- Q[2]
  df2$lwr[SAM] <- Q[1]
  df2$upr[SAM] <- Q[3]
}

print(df2[c(2,1,4,3,6,5,8,7), ])
```

Sammenlignet med resultatet over:

```{r}
#| echo: FALSE

print(df[c(2,1,4,3,6,5,8,7), ])
```
